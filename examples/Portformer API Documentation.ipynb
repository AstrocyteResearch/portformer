{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portformer API Documentation\n",
    "\n",
    "This notebook should document all common use cases and workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from portformer.beta import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User data\n",
    "\n",
    "users can upload \n",
    " * **portfolio**:  \n",
    "   * (portfolio_id, firm_id, user_id, client_id, name, description, tags)\n",
    "   * (ticker, shares, amount, currency, as_of_date, buckets, tags, note)\n",
    " * **trades**:\n",
    "   * (portfolio_id, firm_id, user_id, client_id, name, description, tags)\n",
    "   * (ticker, change_shares, amount, currency, price, mid_price?, fees?)\n",
    " * **todo** (other tables from the backtesters)\n",
    "\n",
    " * **series**: \n",
    "   * (series_id, firm_id, user_id, custom_ticker, name, description, tags, source, asset_class)\n",
    "   * (series_id, as_of_date, high, low, open, close, volume)\n",
    " \n",
    " * **model**:\n",
    "   * (model_id, firm_id, user_id, name, description, tags, source)\n",
    "   * (model_id, as_of_date, series_id, weight)\n",
    "\n",
    " * **analysis**:\n",
    "   * TODO record\n",
    "\n",
    "## User methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples - analyze portfolio\n",
    "\n",
    "  1. User uploads portfolio:  \n",
    "    * `portfolio = create_portfolio(holdings) or create_portfolio(trades)`\n",
    "    * If missing data on a ticker, require uploading `custom_series` and repeat step 1\n",
    "\n",
    "  2. Add Buckets:\n",
    "    * `portfolio = organize_portfolio(portfolio, window=252, as_of_date=None)`\n",
    "    \n",
    "  3. Create Model:\n",
    "     * `model = create_model_from_portfolio(portfolio, min_distance=1)`\n",
    "     * Creates a model from the buckets provided a min_distance between nodes\n",
    " \n",
    "  4. Analyze Portfoio:\n",
    "    * `stats = analyze_portfolio(portfolio, window=252*5, rolling=22, as_of_date=None)`\n",
    "    * returns stats for each bucket and holding (over total window and on a rolling basis)\n",
    "   \n",
    "  5. Replicate: for each node in tree, score and replicate\n",
    "    * `passive_alternatives = portformer_passive_replacements(holdings, os_date, universe_filters=None)`\n",
    "    * `active_alternatives = portformer_active_replacements(holdings, os_date, universe_filters=None)`\n",
    "    * `portfolio_alternatives = replicate_portfolio(portfolio, stats.navs, os_date, universe='etf')`\n",
    "\n",
    "  6. Generate Alternatives: \n",
    "    * `new_portfolios, proposed_changes = propose_optimized(portfolio, candidates=[passive_alternatives, active_alternatives, portfolio_alternatives], batch=10, priorities=[('fees','desc'), ('drawdown', 1)], feedback=None)`\n",
    "    * Feedback dataframe is a set of relative views between strategies with reasons why (tags, notes)\n",
    "    * Generate `stats`, `portfolio meta` and `holdings fundamental data`\n",
    "    \n",
    "  7. Risk Forecasts:\n",
    "    * `risk_model = portfolio_risk(portfolio, method='breakpoint')`\n",
    "    * `risk_model = portfolio_risk(model, method='historical')`\n",
    "\n",
    "  8. Compare Portfolios:\n",
    "    * `relative_stats = compare(portfolio, portfolio2, risk_model=None)`\n",
    "    * `relative_stats = compare(portfolio, model, risk_model=None)`\n",
    "\n",
    "  9. Align Portfolios\n",
    "    * `new_portfolio, transactions, costs = align(portfolio, model, risk_model=None, max_trades=None, tolerance=None, distance_metric=None)`\n",
    "    * The the larger the transactions that bring the portfolios more closely together the greater the costs.\n",
    "\n",
    "  10. Optimize Portfolio:\n",
    "    * Run Portfolio optimization up to a certain tree depth.  Size leafs below max_depth to `equal` or `inverse_vol` or `market_cap` or another `field`\n",
    "    * Given tickers, holdings and bucketing\n",
    "      * `relative_stats, transactions, costs = compare(portfolio, portfolio2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robinhood example\n",
    "\n",
    "```\n",
    "holdings = get_robin_hood_portfolio()\n",
    "portfolio = create_portfolio(holdings)\n",
    "\n",
    "universe = get_universe(asset_class='etf', **filters)  #\n",
    "universe = filter_universe(universe, **filters)  # filter by price, market cap, volume, etc...\n",
    "\n",
    "risk_model = create_risk_model(universe, method='breakpoint')\n",
    "model = optimize(universe, risk_model=risk_model, method='hrp')\n",
    "\n",
    "relative_stats = compare(portfolio, model, risk_model=risk_model)\n",
    "\n",
    "new_portfolio, txns, costs = align(\n",
    "    portfolio, model, risk_model=risk_model, max_trades=None, tolerance=None, distance_metric='vol_contrib'\n",
    ")\n",
    "\n",
    "# Execute txns\n",
    "execute_robin_hood_trades(txns)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friend's Neural Net Strategy Example\n",
    "```\n",
    "custom_indexes = {}\n",
    "for name in total_returns.columns:\n",
    "    custom_indexes[name] = upload_index(\n",
    "        closes=total_returns[name], \n",
    "        names=name, \n",
    "        descriptions=None, \n",
    "        tags=None, \n",
    "        source='Neural Network',\n",
    "        asset_class=None\n",
    "    )\n",
    "total_returns = total_returns.rename(columns=custom_indexes)\n",
    "universe = total_returns.columns.tolist()\n",
    "\n",
    "risk_model = create_risk_model(universe, method='historical')\n",
    "model = optimize(universe, risk_model=risk_model, method='equal')\n",
    "\n",
    "# Bucket\n",
    "portfolio = initialize_portfolio(model, capital=1_000_000)\n",
    "portfolio = organize_portfolio(portfolio, window=252, as_of_date=None)\n",
    "holdings = portfolio.holdings\n",
    "\n",
    "portfolio_alternatives = replicate_portfolio(portfolio, stats.navs, os_date, universe='etf')\n",
    "\n",
    "# view tree colored by metric\n",
    "# color based on improvement in portfolio stat if its substitutute\n",
    "\n",
    "# Greedy portfolio search\n",
    "portfolio_alternatives_ranked = rank_alternatives_by_tree(\n",
    "    portfolio,\n",
    "    candidates=portfolio_alternatives, \n",
    "    algo='gready', \n",
    "    metric='sharpe'\n",
    ")\n",
    "\n",
    "new_portfolios, proposed_changes = propose_optimized(\n",
    "    portfolio, \n",
    "    candidates=portfolio_alternatives, \n",
    "    batch=10, \n",
    "    priorities=[('fees','desc'), ('drawdown', 1)],\n",
    "    feedback=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rose.AI / Quiver Example\n",
    "```\n",
    "signal = get_quiver_sentiment_metric_by_ticker()\n",
    "universe = signal.columns.tolist()\n",
    "\n",
    "base_risk_model = create_risk_model(universe, method='historical')\n",
    "risk_model = base_risk_model.copy()\n",
    "\n",
    "# Create trading factor from sentiment\n",
    "factor = (signal.rolling(window=2).diff() > 0) * 1\n",
    "\n",
    "# Update forecasts\n",
    "risk_model.mu *= factor\n",
    "\n",
    "# Create weights\n",
    "base_model = optimize(universe, risk_model=base_risk_model, method='iv')\n",
    "model = optimize(universe, risk_model=risk_model, method='iv')\n",
    "\n",
    "# View Stats\n",
    "base_stats = analyze_portfolio(base_model, window=252*5, rolling=22, as_of_date=None)\n",
    "stats = analyze_portfolio(model, window=252*5, rolling=22, as_of_date=None)\n",
    "relative_stats = compare(base_model, model, risk_model=base_risk_model)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volos Integration\n",
    "\n",
    "The ability to generate a sector rotation + `SPY/AGG` strategies\n",
    "\n",
    "```\n",
    "universe = ['SPY', 'AGG']\n",
    "# or\n",
    "universe = ['XLC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE', 'XLK', 'XLU']\n",
    "\n",
    "risk_model = create_risk_model(universe, method='breakpoint')\n",
    "model = optimize(universe, risk_model=risk_model, method='hrp')\n",
    "\n",
    "model_id = save_model(model)\n",
    "\n",
    "model = get_model(model_id)\n",
    "portfolio = initialize_portfolio(model, capital=1_000_000)\n",
    "stats = analyze_portfolio(portfolio, window=252*5, rolling=22, as_of_date=None)\n",
    "\n",
    "weights = get_model_weights(model_id, ref_period)\n",
    "\n",
    "# Execute txns\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as_of_date</th>\n",
       "      <th>XLC</th>\n",
       "      <th>XLY</th>\n",
       "      <th>XLP</th>\n",
       "      <th>XLE</th>\n",
       "      <th>XLF</th>\n",
       "      <th>XLV</th>\n",
       "      <th>XLI</th>\n",
       "      <th>XLB</th>\n",
       "      <th>XLRE</th>\n",
       "      <th>XLK</th>\n",
       "      <th>XLU</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as_of_date</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [XLC, XLY, XLP, XLE, XLF, XLV, XLI, XLB, XLRE, XLK, XLU]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tickers =['XLC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE', 'XLK', 'XLU']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RiskModel(breakpoint) - 11 tickers <BusinessDay> (2020-01-01 00:00:00, 2020-10-09 00:00:00)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def API_get_total_returns():\n",
    "    pass\n",
    "\n",
    "def get_total_returns(\n",
    "    tickers,\n",
    "    start=None, \n",
    "    end=None,\n",
    "    freq='B'\n",
    "):\n",
    "    date_range = pd.date_range(\n",
    "        start=start, \n",
    "        end=end,\n",
    "        freq=freq,\n",
    "        name='as_of_date'\n",
    "    )\n",
    "    return pd.DataFrame([], columns=tickers, index=date_range)\n",
    "\n",
    "\n",
    "class RiskModel(object):\n",
    "    def __init__(self, \n",
    "                 total_returns: pd.DataFrame = None, \n",
    "                 tickers: List[str] = None, \n",
    "                 method='historical',\n",
    "                 date_range_start=None, \n",
    "                 date_range_end=None,\n",
    "                 date_range_freq='B',\n",
    "                 date_range_name='as_of_date',\n",
    "                 **kwargs):\n",
    "        \n",
    "        if total_returns is not None:\n",
    "            self.date_range = total_returns.index\n",
    "            self.tickers = total_returns.columns.tolist()\n",
    "        else:\n",
    "            total_returns = get_total_returns(\n",
    "                tickers,\n",
    "                start=date_range_start, \n",
    "                end=date_range_end,\n",
    "                freq=date_range_freq\n",
    "            )            \n",
    "            self.tickers = tickers\n",
    "\n",
    "        date_range_kwargs = {\n",
    "            k.replace('date_range_', ''): v for k, v in kwargs.items() if k.startswith('date_range_')\n",
    "        }\n",
    "        self.date_range = pd.date_range(\n",
    "            start=date_range_start, \n",
    "            end=date_range_end,\n",
    "            freq=date_range_freq,\n",
    "            name=date_range_name,\n",
    "            **date_range_kwargs\n",
    "        )\n",
    "\n",
    "        self.method = method\n",
    "        self.params = kwargs\n",
    "        self.data = total_returns\n",
    "        \n",
    "        self.mu = pd.DataFrame(None, columns=tickers, index=self.date_range)\n",
    "        self.vol = pd.DataFrame(None, columns=tickers, index=self.date_range)\n",
    "        \n",
    "        self.correl = pd.DataFrame(\n",
    "            None, \n",
    "            columns=pd.Index(tickers, name='as_of_date'), \n",
    "            index=pd.MultiIndex.from_tuples([], names=['as_of_date','ticker'])\n",
    "        )\n",
    "        \n",
    "    def transform_data(self, tform='log-diff'):\n",
    "        if tform=='log-diff':\n",
    "            rtns = np.log(self.data).diff().dropna(how='all').fillna(0)\n",
    "        else:\n",
    "            rtns = self.data.diff().dropna(how='all').fillna(0)\n",
    "        return rtns\n",
    "\n",
    "    def get_mu(self, tform='log-diff', **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def get_vol(self, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def get_correl(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def calculate_risks(self, tform='log-diff', **kwargs):\n",
    "        rtns = self.transform_data(tform=tform)\n",
    "        self.mu = self.get_mu(rtns, **kwargs)\n",
    "        self.vol = self.get_vol(rtns, **kwargs)        \n",
    "        self.correl = self.get_correl(rtns, **kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        if len(self.mu):\n",
    "            date_range = '{} ({}, {})'.format(\n",
    "                self.date_range.freq or '',\n",
    "                self.mu.index.min(),\n",
    "                self.mu.index.max()\n",
    "            )\n",
    "        else:\n",
    "            date_range = ''\n",
    "        return 'RiskModel({}) - {} tickers {}'.format(\n",
    "            self.method,\n",
    "            len(self.tickers),\n",
    "            date_range\n",
    "        ).strip()\n",
    "\n",
    "def get_breakpoints(tickers, start=None, end=None):\n",
    "    pass\n",
    "\n",
    "class BreakpointRiskModel(RiskModel):\n",
    "    \n",
    "    self.bps = None\n",
    "    self.meta = {}\n",
    "\n",
    "    def get_correl(self, **kwargs):\n",
    "        \"\"\"For each day calculates cosine similarity of \n",
    "        breakpoints * (2*sharpe_pvalue - 1)\n",
    "        \"\"\" \n",
    "        pass\n",
    "    \n",
    "    def calculate_risks(self, **kwargs):\n",
    "        self.bps = get_breakpoints(self.tickers)\n",
    "        self.mu = pd.pivot_table(self.bps, index='as_of_date', columns='ticker', values='mu')\n",
    "        self.vol = pd.pivot_table(self.bps, index='as_of_date', columns='ticker', values='vol')\n",
    "        self.correl = self.get_correl(rtns, **kwargs)\n",
    "\n",
    "    \n",
    "\n",
    "def create_risk_model(total_returns=None, tickers: List[str]=None, method='historical', **kwargs):\n",
    "    if method == 'historical':\n",
    "        return RiskModel(total_returns=total_returns, tickers=tickers, method=method, **kwargs)\n",
    "    elif method == 'breakpoint':\n",
    "        return BreakpointRiskModel(total_returns=total_returns, tickers=tickers, method=method, **kwargs)\n",
    "    else:\n",
    "        raise NotImplementedError(\"method must be either `historical` or `breakpoint`\")\n",
    "\n",
    "\n",
    "universe = ['XLC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE', 'XLK', 'XLU']\n",
    "\n",
    "risk_model = create_risk_model(\n",
    "    tickers=universe,\n",
    "    method='breakpoint',\n",
    "    date_range_start='2020-01-01',\n",
    "    date_range_end='2020-10-10'\n",
    ")\n",
    "risk_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-88ca41c9d2d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mrisk_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_risk_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'breakpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrisk_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hrp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimize' is not defined"
     ]
    }
   ],
   "source": [
    "model = optimize(universe, risk_model=risk_model, method='hrp')\n",
    "\n",
    "model_id = save_model(model)\n",
    "\n",
    "model = get_model(model_id)\n",
    "portfolio = initialize_portfolio(model, capital=1_000_000)\n",
    "stats = analyze_portfolio(portfolio, window=252*5, rolling=22, as_of_date=None)\n",
    "\n",
    "weights = get_model_weights(model_id, ref_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('portformer_venv': venv)",
   "language": "python",
   "name": "python37664bitportformervenvvenvbc2a7ff0feeb4e748530fb450a915c7d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
